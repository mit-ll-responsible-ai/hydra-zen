
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="hydra-zen can be used to design a boilerplate-free Hydra application for running PyTorch Lightning experiments." name="description"/>
<link href="../_static/hydra_zen_favicon_32x32.png" rel="icon" sizes="-1x-1" type="image/png"/>
<link href="../_static/hydra_zen_favicon_64x64.png" rel="icon" sizes="-1x-1" type="image/png"/>
<title>Run Boilerplate-Free ML Experiments with PyTorch Lightning &amp; hydra-zen — hydra-zen  documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet">
<link href="../_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css?v=a746c00c" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-codeautolink.css?v=125d5c1c" rel="stylesheet" type="text/css"/>
<link href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" rel="preload"/>
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" rel="preload"/>
<script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>
<script src="../_static/documentation_options.js?v=5929fcd5"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=30646c52"></script>
<script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-115029372-2"></script>
<script src="../_static/gtag.js?v=dff6cbd6"></script>
<script src="../_static/design-tabs.js?v=36754332"></script>
<script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'how_to/pytorch_lightning';</script>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../explanation.html" rel="next" title="Explanation"/>
<link href="using_scikit_learn.html" rel="prev" title="Configure and Run scikit-learn’s Classifier Comparison Example"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<a class="skip-link" href="#main-content">Skip to main content</a>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>
<input class="sidebar-toggle" id="__primary" name="__primary" type="checkbox"/>
<label class="overlay overlay-primary" for="__primary"></label>
<input class="sidebar-toggle" id="__secondary" name="__secondary" type="checkbox"/>
<label class="overlay overlay-secondary" for="__secondary"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
<label class="sidebar-toggle primary-toggle" for="__primary">
<span class="fa-solid fa-bars"></span>
</label>
<div class="col-lg-3 navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../index.html">
<img alt="hydra-zen  documentation - Home" class="logo__image only-light" src="../_static/Hydra-Zen_logo_full_light_blue.png"/>
<script>document.write(`<img src="../_static/Hydra-Zen_logo_full_light_blue.png" class="logo__image only-dark" alt="hydra-zen  documentation - Home"/>`);</script>
</a></div>
</div>
<div class="col-lg-9 navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item"><nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
    Site Navigation
  </p>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../tutorials.html">
                        Tutorials
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../how_tos.html">
                        How-To Guides
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../explanation.html">
                        Explanation
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../api_reference.html">
                        Reference
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../changes.html">
                        Changelog
                      </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item navbar-persistent--container">
<script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links navbar-nav">
<li class="nav-item">
<a class="nav-link" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/mit-ll-responsible-ai/hydra-zen" rel="noopener" target="_blank" title="GitHub"><span><i aria-hidden="true" class="fab fa-github-square fa-lg"></i></span>
<span class="sr-only">GitHub</span></a>
</li>
</ul></div>
</div>
</div>
<div class="navbar-persistent--mobile">
<script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
</div>
<label class="sidebar-toggle secondary-toggle" for="__secondary" tabindex="0">
<span class="fa-solid fa-outdent"></span>
</label>
</div>
</nav>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item"><nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
    Site Navigation
  </p>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../tutorials.html">
                        Tutorials
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../how_tos.html">
                        How-To Guides
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../explanation.html">
                        Explanation
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../api_reference.html">
                        Reference
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../changes.html">
                        Changelog
                      </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links navbar-nav">
<li class="nav-item">
<a class="nav-link" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/mit-ll-responsible-ai/hydra-zen" rel="noopener" target="_blank" title="GitHub"><span><i aria-hidden="true" class="fab fa-github-square fa-lg"></i></span>
<span class="sr-only">GitHub</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item"><nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="configuring_experiments.html">Configure Multiple Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="configure_hydra.html">Customize Hydra’s Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="partial_config.html">Partially Configure an Object</a></li>
<li class="toctree-l1"><a class="reference internal" href="beartype.html">Add Enhanced Runtime Type-Checking to a Hydra App</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_scikit_learn.html">Configure and Run scikit-learn’s Classifier Comparison Example</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Run Boilerplate-Free ML Experiments with PyTorch Lightning &amp; hydra-zen</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../how_tos.html">How-To Guides</a></li>
<li aria-current="page" class="breadcrumb-item active">Run...</li>
</ul>
</nav>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article" role="main">
<div class="admonition-prerequisites admonition" id="lightning">
<p class="admonition-title">Prerequisites</p>
<p>Your must install <a class="reference external" href="https://pytorch.org/">PyTorch</a> and <a class="reference external" href="https://www.pytorchlightning.ai/">PyTorch Lightning</a> in your Python environment in order to follow this
How-To guide.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Using hydra-zen for your research project? <a class="reference external" href="https://zenodo.org/record/5584711">Cite us</a>! 😊</p>
</div>
<section id="run-boilerplate-free-ml-experiments-with-pytorch-lightning-hydra-zen">
<h1>Run Boilerplate-Free ML Experiments with PyTorch Lightning &amp; hydra-zen<a class="headerlink" href="#run-boilerplate-free-ml-experiments-with-pytorch-lightning-hydra-zen" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://www.pytorchlightning.ai/">PyTorch Lightning</a> is a library designed to
eliminate the boilerplate code that is associated with training and testing neural
networks in PyTorch. This is a natural bedfellow of Hydra and hydra-zen, which eliminate the boilerplate associated with designing software that is configurable, repeatable, and scalable.</p>
<p>Let’s use Hydra, hydra-zen, and PyTorch Lightning to <strong>configure and train multiple
single-layer neural networks without any boilerplate code</strong>. For the sake of
simplicity, we will train it to simply fit <span class="math notranslate nohighlight">\(\cos{x}\)</span> on
<span class="math notranslate nohighlight">\(x \in [-2\pi, 2\pi]\)</span>.</p>
<p>In this “How-To” we will do the following:</p>
<ol class="arabic simple">
<li><p>Define a simple neural network and <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html">lightning module</a>.</p></li>
<li><p>Create configs for our lighting module, data loader, optimizer, and trainer.</p></li>
<li><p>Define a task-function for training and testing a model.</p></li>
<li><p>Train four different models using combinations of two batch-sizes and two model-sizes (i.e. the number of neurons).</p></li>
<li><p>Analyze our models’ results.</p></li>
<li><p>Load our best model using the checkpoints saved by PyTorch Lightning and the job-config saved by Hydra.</p></li>
</ol>
<section id="defining-our-model">
<h2>Defining Our Model<a class="headerlink" href="#defining-our-model" title="Link to this heading">#</a></h2>
<p>Create a script called <code class="docutils literal notranslate"><span class="pre">zen_model.py</span></code> (or, open a Jupyter notebook and include the
following code. Here, we define our single-layer neural network and the <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html">lightning module</a> that describes how to train and evaluate our model.</p>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">Contents of <code class="docutils literal notranslate"><span class="pre">zen_model.py</span></code></span><a class="headerlink" href="#id3" title="Link to this code">#</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/typing.html#module-typing" title="typing"><span class="nn">typing</span></a> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="typing.Callable"><span class="n">Callable</span></a><span class="p">,</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/typing.html#typing.Type" title="typing.Type"><span class="n">Type</span></a>

<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">tr</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Optimizer</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>

<span class="kn">from</span> <span class="nn">hydra_zen.typing</span> <span class="kn">import</span> <span class="n">Partial</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"UniversalFuncModule"</span><span class="p">,</span> <span class="s2">"single_layer_nn"</span><span class="p">,</span> <span class="s2">"train_and_eval"</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">single_layer_nn</span><span class="p">(</span><span class="n">num_neurons</span><span class="p">:</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/functions.html#int" title="int"><span class="nb">int</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""y = sum(V sigmoid(X W + b))"""</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_neurons</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_neurons</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="p">)</span>


<span class="k">class</span> <span class="nc">UniversalFuncModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">optim</span><span class="p">:</span> <span class="n">Partial</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">],</span>
        <span class="n">dataloader</span><span class="p">:</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/typing.html#typing.Type" title="typing.Type"><span class="n">Type</span></a><span class="p">[</span><span class="n">DataLoader</span><span class="p">],</span>
        <span class="n">target_fn</span><span class="p">:</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="typing.Callable"><span class="n">Callable</span></a><span class="p">[[</span><span class="n">tr</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">tr</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">training_domain</span><span class="p">:</span> <span class="n">tr</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">):</span>
        <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/functions.html#super" title="super"><span class="nb">super</span></a><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">optim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">dataloader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_domain</span> <span class="o">=</span> <span class="n">training_domain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_fn</span> <span class="o">=</span> <span class="n">target_fn</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># provide optimizer with model parameters</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="c1"># compute |cos(x) - model(x)|^2</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># generate dataset: x, cos(x)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_domain</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_fn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataloader</span><span class="p">(</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">train_and_eval</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">tr</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">optim</span><span class="p">:</span> <span class="n">Partial</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">],</span>
    <span class="n">dataloader</span><span class="p">:</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/typing.html#typing.Type" title="typing.Type"><span class="n">Type</span></a><span class="p">[</span><span class="n">DataLoader</span><span class="p">],</span>
    <span class="n">target_fn</span><span class="p">:</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="typing.Callable"><span class="n">Callable</span></a><span class="p">[[</span><span class="n">tr</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">tr</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">training_domain</span><span class="p">:</span> <span class="n">tr</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">lit_module</span><span class="p">:</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/typing.html#typing.Type" title="typing.Type"><span class="n">Type</span></a><span class="p">[</span><span class="n">UniversalFuncModule</span><span class="p">],</span>
    <span class="n">trainer</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">,</span>
<span class="p">):</span>


    <span class="n">lit</span> <span class="o">=</span> <span class="n">lit_module</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">optim</span><span class="o">=</span><span class="n">optim</span><span class="p">,</span>
        <span class="n">dataloader</span><span class="o">=</span><span class="n">dataloader</span><span class="p">,</span>
        <span class="n">target_fn</span><span class="o">=</span><span class="n">target_fn</span><span class="p">,</span>
        <span class="n">training_domain</span><span class="o">=</span><span class="n">training_domain</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># train the model</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">lit</span><span class="p">)</span>

    <span class="c1"># evaluate the model over the domain to assess the fit</span>
    <span class="n">final_eval</span> <span class="o">=</span> <span class="n">lit</span><span class="p">(</span><span class="n">training_domain</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">final_eval</span> <span class="o">=</span> <span class="n">final_eval</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="c1"># return the final evaluation of our model:</span>
    <span class="c1"># a shape-(N,) numpy-array</span>
    <span class="k">return</span> <span class="n">final_eval</span>
</pre></div>
</div>
</div>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p><a class="reference external" href="https://www.pythonlikeyoumeanit.com/Module5_OddsAndEnds/Writing_Good_Code.html#Type-Hinting">Type-annotations</a> are <strong>not</strong> required by hydra-zen. However, they do enable <a class="reference internal" href="../explanation/type_refinement.html#type-support"><span class="std std-ref">runtime type-checking of configured values</span></a> for our app.</p>
</div>
</section>
<section id="creating-our-configs-and-task-function">
<h2>Creating Our Configs and Task Function<a class="headerlink" href="#creating-our-configs-and-task-function" title="Link to this heading">#</a></h2>
<p>Create another script - named <code class="docutils literal notranslate"><span class="pre">experiment.py</span></code> - in the same directory as <code class="docutils literal notranslate"><span class="pre">zen_model.py</span></code>.
Here, we will create the configs for our optimizer, model, data-loader, lightning module,
and trainer. We’ll also define the task function that trains and tests our model.</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">Contents of <code class="docutils literal notranslate"><span class="pre">experiment.py</span></code></span><a class="headerlink" href="#id4" title="Link to this code">#</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/math.html#module-math" title="math"><span class="nn">math</span></a> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/math.html#math.pi" title="math.pi"><span class="n">pi</span></a>

<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">from</span> <span class="nn">hydra_zen</span> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.builds.html#hydra_zen.builds" title="hydra_zen.builds"><span class="n">builds</span></a><span class="p">,</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.make_config.html#hydra_zen.make_config" title="hydra_zen.make_config"><span class="n">make_config</span></a><span class="p">,</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.make_custom_builds_fn.html#hydra_zen.make_custom_builds_fn" title="hydra_zen.make_custom_builds_fn"><span class="n">make_custom_builds_fn</span></a><span class="p">,</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.zen.html#hydra_zen.zen" title="hydra_zen.zen"><span class="n">zen</span></a>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">tr</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">zen_model</span> <span class="kn">import</span> <span class="n">UniversalFuncModule</span><span class="p">,</span> <span class="n">train_and_eval</span><span class="p">,</span> <span class="n">single_layer_nn</span>

<span class="n">pbuilds</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.make_custom_builds_fn.html#hydra_zen.make_custom_builds_fn" title="hydra_zen.make_custom_builds_fn"><span class="n">make_custom_builds_fn</span></a><span class="p">(</span><span class="n">zen_partial</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">populate_full_signature</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="n">ExperimentConfig</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.make_config.html#hydra_zen.make_config" title="hydra_zen.make_config"><span class="n">make_config</span></a><span class="p">(</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">lit_module</span><span class="o">=</span><span class="n">UniversalFuncModule</span><span class="p">,</span>
    <span class="n">trainer</span><span class="o">=</span><a class="sphinx-codeautolink-a" href="../generated/hydra_zen.builds.html#hydra_zen.builds" title="hydra_zen.builds"><span class="n">builds</span></a><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span>
    <span class="n">model</span><span class="o">=</span><a class="sphinx-codeautolink-a" href="../generated/hydra_zen.builds.html#hydra_zen.builds" title="hydra_zen.builds"><span class="n">builds</span></a><span class="p">(</span><span class="n">single_layer_nn</span><span class="p">,</span> <span class="n">num_neurons</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">optim</span><span class="o">=</span><span class="n">pbuilds</span><span class="p">(</span><span class="n">Adam</span><span class="p">),</span>
    <span class="n">dataloader</span><span class="o">=</span><span class="n">pbuilds</span><span class="p">(</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">target_fn</span><span class="o">=</span><span class="n">tr</span><span class="o">.</span><span class="n">cos</span><span class="p">,</span>
    <span class="n">training_domain</span><span class="o">=</span><a class="sphinx-codeautolink-a" href="../generated/hydra_zen.builds.html#hydra_zen.builds" title="hydra_zen.builds"><span class="n">builds</span></a><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">linspace</span><span class="p">,</span> <span class="n">start</span><span class="o">=-</span><span class="mi">2</span> <span class="o">*</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/math.html#math.pi" title="math.pi"><span class="n">pi</span></a><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/math.html#math.pi" title="math.pi"><span class="n">pi</span></a><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Wrapping `train_and_eval` with `zen` makes it compatible with Hydra as a task function</span>
<span class="c1">#</span>
<span class="c1"># We must specify `pre_call` to ensure that pytorch lightning seeds everything</span>
<span class="c1"># *before* any of our configs are instantiated (which will initialize the pytorch</span>
<span class="c1"># model whose weights depend on the seed)</span>
<span class="n">pre_seed</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.zen.html#hydra_zen.zen" title="hydra_zen.zen"><span class="n">zen</span></a><span class="p">(</span><span class="k">lambda</span> <span class="n">seed</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">seed_everything</span><span class="p">(</span><span class="n">seed</span><span class="p">))</span>
<span class="n">task_function</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.zen.html#hydra_zen.zen" title="hydra_zen.zen"><span class="n">zen</span></a><span class="p">(</span><span class="n">train_and_eval</span><span class="p">,</span> <span class="n">pre_call</span><span class="o">=</span><span class="n">pre_seed</span><span class="p">)</span>

<span class="k">if</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/reference/import.html#name__" title="__name__"><span class="vm">__name__</span></a> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="c1"># enables us to call</span>
    <span class="kn">from</span> <span class="nn">hydra_zen</span> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.ZenStore.html#hydra_zen.ZenStore" title="hydra_zen.wrapper._implementations.ZenStore"><span class="n">ZenStore</span></a>

    <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.ZenStore.html#hydra_zen.ZenStore" title="hydra_zen.wrapper._implementations.ZenStore"><span class="n">store</span></a> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.ZenStore.html#hydra_zen.ZenStore" title="hydra_zen.wrapper._implementations.ZenStore"><span class="n">ZenStore</span></a><span class="p">(</span><span class="n">deferred_hydra_store</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.ZenStore.html#hydra_zen.ZenStore" title="hydra_zen.wrapper._implementations.ZenStore"><span class="n">store</span></a><span class="p">(</span><span class="n">ExperimentConfig</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"lit_app"</span><span class="p">)</span>

    <span class="n">task_function</span><span class="o">.</span><span class="n">hydra_main</span><span class="p">(</span>
        <span class="n">config_name</span><span class="o">=</span><span class="s2">"lit_app"</span><span class="p">,</span>
        <span class="n">version_base</span><span class="o">=</span><span class="s2">"1.1"</span><span class="p">,</span>
        <span class="n">config_path</span><span class="o">=</span><span class="s2">"."</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-be-mindful-of-what-your-task-function-returns admonition">
<p class="admonition-title">Be Mindful of What Your Task Function Returns</p>
<p>We <em>could</em> make this <code class="xref py py-obj docutils literal notranslate"><span class="pre">train_and_eval</span></code> return our trained neural network, which would enable
convenient access to it, in-memory, after our Hydra job completes. However, launching this
task function in a multirun fashion will train multiple models and thus would keep <em>all</em> of
those models in-memory (and perhaps on-GPU) simultaneously!</p>
<p>By not returning the model from our task function, we avoid the risk of hitting out-of-memory
errors when training multiple large models.</p>
</div>
</section>
<section id="running-our-experiments">
<h2>Running Our Experiments<a class="headerlink" href="#running-our-experiments" title="Link to this heading">#</a></h2>
<p>We will use <a class="reference internal" href="../generated/hydra_zen.launch.html#hydra_zen.launch" title="hydra_zen.launch"><code class="xref py py-func docutils literal notranslate"><span class="pre">hydra_zen.launch()</span></code></a> to run four jobs: training our model with all four combinations of:</p>
<ul class="simple">
<li><p>a batch-size of 20 and 200</p></li>
<li><p>a model with 10 and 100 neurons</p></li>
</ul>
<p>Open a Python console (or Jupyter notebook) in the same directory as <code class="docutils literal notranslate"><span class="pre">experiment.py</span></code>
and run the following code.</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">Launching four jobs from a Python console.</span><a class="headerlink" href="#id5" title="Link to this code">#</a></div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">hydra_zen</span> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.launch.html#hydra_zen.launch" title="hydra_zen.launch"><span class="n">launch</span></a>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">experiment</span> <span class="kn">import</span> <span class="n">ExperimentConfig</span><span class="p">,</span> <span class="n">task_function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">jobs</span><span class="p">,)</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.launch.html#hydra_zen.launch" title="hydra_zen.launch"><span class="n">launch</span></a><span class="p">(</span>
<span class="gp">... </span>    <span class="n">ExperimentConfig</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">task_function</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">overrides</span><span class="o">=</span><span class="p">[</span>
<span class="gp">... </span>        <span class="s2">"dataloader.batch_size=20,200"</span><span class="p">,</span>
<span class="gp">... </span>        <span class="s2">"model.num_neurons=10,100"</span><span class="p">,</span>
<span class="gp">... </span>    <span class="p">],</span>
<span class="gp">... </span>    <span class="n">multirun</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="go">[2021-10-24 21:23:32,556][HYDRA] Launching 4 jobs locally</span>
<span class="go">[2021-10-24 21:23:32,558][HYDRA]     #0 : dataloader.batch_size=20 model.num_neurons=10</span>
<span class="go">[2021-10-24 21:23:45,809][HYDRA]     #1 : dataloader.batch_size=20 model.num_neurons=100</span>
<span class="go">[2021-10-24 21:23:58,656][HYDRA]     #2 : dataloader.batch_size=200 model.num_neurons=10</span>
<span class="go">[2021-10-24 21:24:01,796][HYDRA]     #3 : dataloader.batch_size=200 model.num_neurons=100</span>
</pre></div>
</div>
</div>
<p>Keep this Python console open; we will be making use of <code class="docutils literal notranslate"><span class="pre">jobs</span></code> in order to inspect
our results.</p>
<p>Note that this is equivalent to running the following from the CLI:</p>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">Launching four jobs from the CLI.</span><a class="headerlink" href="#id6" title="Link to this code">#</a></div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>python<span class="w"> </span>experiment.py<span class="w"> </span>dataloader.batch_size<span class="o">=</span><span class="m">20</span>,200<span class="w"> </span>model.num_neurons<span class="o">=</span><span class="m">10</span>,100<span class="w"> </span>-m
<span class="go">[2021-10-24 21:23:32,556][HYDRA] Launching 4 jobs locally</span>
<span class="gp">[2021-10-24 21:23:32,558][HYDRA]     #</span><span class="m">0</span><span class="w"> </span>:<span class="w"> </span>dataloader.batch_size<span class="o">=</span><span class="m">20</span><span class="w"> </span>model.num_neurons<span class="o">=</span><span class="m">10</span>
<span class="gp">[2021-10-24 21:23:45,809][HYDRA]     #</span><span class="m">1</span><span class="w"> </span>:<span class="w"> </span>dataloader.batch_size<span class="o">=</span><span class="m">20</span><span class="w"> </span>model.num_neurons<span class="o">=</span><span class="m">100</span>
<span class="gp">[2021-10-24 21:23:58,656][HYDRA]     #</span><span class="m">2</span><span class="w"> </span>:<span class="w"> </span>dataloader.batch_size<span class="o">=</span><span class="m">200</span><span class="w"> </span>model.num_neurons<span class="o">=</span><span class="m">10</span>
<span class="gp">[2021-10-24 21:24:01,796][HYDRA]     #</span><span class="m">3</span><span class="w"> </span>:<span class="w"> </span>dataloader.batch_size<span class="o">=</span><span class="m">200</span><span class="w"> </span>model.num_neurons<span class="o">=</span><span class="m">100</span>
</pre></div>
</div>
</div>
</section>
<section id="inspecting-our-results">
<h2>Inspecting Our Results<a class="headerlink" href="#inspecting-our-results" title="Link to this heading">#</a></h2>
<section id="visualizing-our-results">
<h3>Visualizing Our Results<a class="headerlink" href="#visualizing-our-results" title="Link to this heading">#</a></h3>
<p>Let’s begin inspecting our results by plotting our four models on <span class="math notranslate nohighlight">\(x \in [-2\pi, 2\pi]\)</span>, alongside the
target function: <span class="math notranslate nohighlight">\(\cos{x}\)</span>. Continuing to work in our current Python console (or Jupyter notebook), run
the following code and verify that you see the plot shown below.</p>
<div class="literal-block-wrapper docutils container" id="id7">
<div class="code-block-caption"><span class="caption-text">Plotting our models</span><a class="headerlink" href="#id7" title="Link to this code">#</a></div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">hydra_zen</span> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.instantiate.html#hydra_zen.instantiate" title="hydra_zen.instantiate"><span class="n">instantiate</span></a>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">matplotlib.axes</span> <span class="kn">import</span> <span class="n">Axes</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.instantiate.html#hydra_zen.instantiate" title="hydra_zen.instantiate"><span class="n">instantiate</span></a><span class="p">(</span><span class="n">ExperimentConfig</span><span class="o">.</span><span class="n">training_domain</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_fn</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.instantiate.html#hydra_zen.instantiate" title="hydra_zen.instantiate"><span class="n">instantiate</span></a><span class="p">(</span><span class="n">ExperimentConfig</span><span class="o">.</span><span class="n">target_fn</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/functions.html#isinstance" title="isinstance"><span class="nb">isinstance</span></a><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">Axes</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">target_fn</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">ls</span><span class="o">=</span><span class="s2">"--"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Target"</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">jobs</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">out</span> <span class="o">=</span> <span class="n">j</span><span class="o">.</span><span class="n">return_value</span>
<span class="gp">... </span>    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">","</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"."</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">j</span><span class="o">.</span><span class="n">overrides</span><span class="p">))</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.04</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s2">"upper left"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<a class="reference internal image-reference" href="https://user-images.githubusercontent.com/29104956/138622935-3a3a960f-301f-477e-b5ab-7f4c741b1f9e.png"><img alt="Plot of four trained models vs the target function" src="https://user-images.githubusercontent.com/29104956/138622935-3a3a960f-301f-477e-b5ab-7f4c741b1f9e.png" style="width: 800px;"/></a>
</section>
<section id="loading-the-model-of-best-fit">
<h3>Loading the Model of Best-Fit<a class="headerlink" href="#loading-the-model-of-best-fit" title="Link to this heading">#</a></h3>
<p>The 100-neuron model trained with a batch-size of 20 best fits our target function.
Let’s load the model weights that were saved by PyTorch Lightning during training.</p>
<p>Continuing our work in the same Python console, let’s verify that job-1 corresponds to
our desired model. Verify that you see the following outputs.</p>
<div class="literal-block-wrapper docutils container" id="id8">
<div class="code-block-caption"><span class="caption-text">Job 1 corresponds to the 100-neuron model trained with batch-size 20.</span><a class="headerlink" href="#id8" title="Link to this code">#</a></div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">best</span> <span class="o">=</span> <span class="n">jobs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">batch_size</span>
<span class="go">20</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">num_neurons</span>
<span class="go">100</span>
</pre></div>
</div>
</div>
<p>Next, we’ll load the config for this job. Recall that Hydra saves a <code class="docutils literal notranslate"><span class="pre">.hydra/config.yaml</span></code> file, which contains the complete configuration of this job – we can reproduce
all aspects of it from this YAML.</p>
<div class="literal-block-wrapper docutils container" id="id9">
<div class="code-block-caption"><span class="caption-text">Loading the complete config for this job</span><a class="headerlink" href="#id9" title="Link to this code">#</a></div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">hydra_zen</span> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.load_from_yaml.html#hydra_zen.load_from_yaml" title="hydra_zen.load_from_yaml"><span class="n">load_from_yaml</span></a><span class="p">,</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.get_target.html#hydra_zen.get_target" title="hydra_zen.get_target"><span class="n">get_target</span></a><span class="p">,</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.to_yaml.html#hydra_zen.to_yaml" title="hydra_zen.to_yaml"><span class="n">to_yaml</span></a>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/pathlib.html#module-pathlib" title="pathlib"><span class="nn">pathlib</span></a> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path"><span class="n">Path</span></a>

<span class="gp">&gt;&gt;&gt; </span><a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path"><span class="n">outdir</span></a> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path"><span class="n">Path</span></a><span class="p">(</span><span class="n">best</span><span class="o">.</span><span class="n">working_dir</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cfg</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.load_from_yaml.html#hydra_zen.load_from_yaml" title="hydra_zen.load_from_yaml"><span class="n">load_from_yaml</span></a><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="pathlib.Path"><span class="n">outdir</span></a> <span class="o">/</span> <span class="s2">".hydra"</span> <span class="o">/</span> <span class="s2">"config.yaml"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>It is worth printing our this config to appreciate all of the exhaustive details that
it captures about this job.</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/functions.html#print" title="print"><span class="nb">print</span></a><span class="p">(</span><span class="n">to_yaml</span><span class="p">(</span><span class="n">cfg</span><span class="p">))</span>  <span class="c1"># fully details this job's config</span>
<span class="go">seed: 1</span>
<span class="go">lit_module:</span>
<span class="go">  path: zen_model.UniversalFuncModule</span>
<span class="go">  _target_: hydra_zen.funcs.get_obj</span>
<span class="go">trainer:</span>
<span class="go">  _target_: pytorch_lightning.trainer.trainer.Trainer</span>
<span class="go">  max_epochs: 100</span>
<span class="go">model:</span>
<span class="go">  _target_: zen_model.single_layer_nn</span>
<span class="go">  num_neurons: 100</span>
<span class="go">optim:</span>
<span class="go">  _target_: torch.optim.adam.Adam</span>
<span class="go">  _partial_: true</span>
<span class="go">  lr: 0.001</span>
<span class="go">  betas:</span>
<span class="go">  - 0.9</span>
<span class="go">  - 0.999</span>
<span class="go">  eps: 1.0e-08</span>
<span class="go">  weight_decay: 0</span>
<span class="go">  amsgrad: false</span>
<span class="go">dataloader:</span>
<span class="go">  _target_: torch.utils.data.dataloader.DataLoader</span>
<span class="go">  _partial_: true</span>
<span class="go">  batch_size: 20</span>
<span class="go">  shuffle: true</span>
<span class="go">  sampler: null</span>
<span class="go">  batch_sampler: null</span>
<span class="go">  num_workers: 0</span>
<span class="go">  collate_fn: null</span>
<span class="go">  pin_memory: false</span>
<span class="go">  drop_last: true</span>
<span class="go">  timeout: 0.0</span>
<span class="go">  worker_init_fn: null</span>
<span class="go">  multiprocessing_context: null</span>
<span class="go">  generator: null</span>
<span class="go">  prefetch_factor: 2</span>
<span class="go">  persistent_workers: false</span>
<span class="go">target_fn:</span>
<span class="go">  path: torch.cos</span>
<span class="go">  _target_: hydra_zen.funcs.get_obj</span>
<span class="go">training_domain:</span>
<span class="go">  _target_: torch.linspace</span>
<span class="go">  start: -6.283185307179586</span>
<span class="go">  end: 6.283185307179586</span>
<span class="go">  steps: 1000</span>
</pre></div>
</div>
<p>PyTorch Lightning saved the model’s trained weights as a <code class="docutils literal notranslate"><span class="pre">.ckpt</span></code> file in this job’s
working directory. Let’s load these weights and use them to instantiate our lighting
module.</p>
<div class="literal-block-wrapper docutils container" id="id10">
<div class="code-block-caption"><span class="caption-text">Loading our lighting module with trained weights</span><a class="headerlink" href="#id10" title="Link to this code">#</a></div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">hydra_zen</span> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.zen.html#hydra_zen.zen" title="hydra_zen.zen"><span class="n">zen</span></a>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/functools.html#module-functools" title="functools"><span class="nn">functools</span></a> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/functools.html#functools.partial" title="functools.partial"><span class="n">partial</span></a>
<span class="gp">&gt;&gt;&gt; </span><span class="o">*</span><span class="n">_</span><span class="p">,</span> <span class="n">last_ckpt</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/functions.html#sorted" title="sorted"><span class="nb">sorted</span></a><span class="p">(</span><span class="n">outdir</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">"**/*.ckpt"</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">LitModule</span> <span class="o">=</span> <span class="n">get_target</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">lit_module</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/functools.html#functools.partial" title="functools.partial"><span class="n">pload</span></a> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/functools.html#functools.partial" title="functools.partial"><span class="n">partial</span></a><span class="p">(</span><span class="n">LitModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">,</span> <span class="n">last_ckpt</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># extract top-level fields from `cfg`, instantiate them, and pass to `load_from_checkpoint`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loaded</span> <span class="o">=</span> <a class="sphinx-codeautolink-a" href="../generated/hydra_zen.zen.html#hydra_zen.zen" title="hydra_zen.zen"><span class="n">zen</span></a><span class="p">(</span><a class="sphinx-codeautolink-a" href="https://docs.python.org/3/library/functools.html#functools.partial" title="functools.partial"><span class="n">pload</span></a><span class="p">,</span> <span class="n">unpack_kwargs</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">cfg</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
</pre></div>
</div>
</div>
<p>Finally, let’s double check that this loaded model behaves as-expected. Evaluating it
at <span class="math notranslate nohighlight">\(-\pi/2\)</span>, <span class="math notranslate nohighlight">\(0\)</span>, and <span class="math notranslate nohighlight">\(\pi/2\)</span> should return, approximately, <span class="math notranslate nohighlight">\(0\)</span>, <span class="math notranslate nohighlight">\(1\)</span>, and <span class="math notranslate nohighlight">\(0\)</span>, respectively.</p>
<div class="literal-block-wrapper docutils container" id="id11">
<div class="code-block-caption"><span class="caption-text">Checkout our loaded model’s behavior</span><a class="headerlink" href="#id11" title="Link to this code">#</a></div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">tr</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loaded</span><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">3.1415</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">3.1415</span> <span class="o">/</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="go">tensor([[0.0110],</span>
<span class="go">        [0.9633],</span>
<span class="go">        [0.0364]], grad_fn=&lt;MmBackward&gt;)</span>
</pre></div>
</div>
</div>
<div class="admonition-math-details admonition">
<p class="admonition-title">Math Details</p>
<p>For the interested reader… In this toy-problem we are optimizing <a class="reference external" href="https://en.wikipedia.org/wiki/Universal_approximation_theorem#Arbitrary-width_case">arbitrary-width universal function approximators</a> to fit <span class="math notranslate nohighlight">\(\cos{x}\)</span>
on <span class="math notranslate nohighlight">\(x \in [-2\pi, 2\pi]\)</span>.
In mathematical notation, we want to solve the following optimization problem:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}F(\vec{v}, \vec{w}, \vec{b}; x) &amp;= \sum_{i=1}^{N}{v_{i}\sigma(x w_i + b_i)}\\\vec{v}^*, \vec{w}^*, \vec{b}^* &amp;= \operatorname*{arg\,min}_{\vec{v}, \vec{w}, \vec   {b}\in\mathbb{R}^{N}} \;  \|F(\vec{v}, \vec{w}, \vec{b}; x)\ - \cos{x}\|_{2}\\x &amp;\in [-2\pi, 2\pi]\end{aligned}\end{align} \]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> – the number of “neurons” in our layer – is a hyperparameter.</p>
</div>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p><strong>Cleaning Up</strong>:
To clean up after this tutorial, delete the <code class="docutils literal notranslate"><span class="pre">multirun</span></code> directory that Hydra
created upon launching our app. You can find this in the same directory as your
<code class="docutils literal notranslate"><span class="pre">experiment.py</span></code> file.</p>
</div>
</section>
</section>
</section>
</article>
<footer class="prev-next-footer">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="using_scikit_learn.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Configure and Run scikit-learn’s Classifier Comparison Example</p>
</div>
</a>
<a class="right-next" href="../explanation.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Explanation</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-our-model">Defining Our Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-our-configs-and-task-function">Creating Our Configs and Task Function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-our-experiments">Running Our Experiments</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inspecting-our-results">Inspecting Our Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-our-results">Visualizing Our Results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-the-model-of-best-fit">Loading the Model of Best-Fit</a></li>
</ul>
</li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="tocsection sourcelink">
<a href="../_sources/how_to/pytorch_lightning.rst.txt">
<i class="fa-solid fa-file-lines"></i> Show Source
    </a>
</div>
</div>
</div></div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2023 Massachusetts Institute of Technology.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.14.3.
</p></div>
</div>
</div>
</footer>
</body>
</html>